{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "accessible-austria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "curious-coordinator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./huggingface_models/')\n",
    "sys.path.append('./utils/')\n",
    "# from sample_utils import *\n",
    "# from inference_utils import *\n",
    "# from leetcode_exec_utils import *\n",
    "# from execution_utils import *\n",
    "from self_training_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ultimate-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "boolean-partition",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_sample, temperature = False, 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rocky-dollar",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_lang_dict, code_id_lang_dic = read_toked_code_dict(code_dict_path)\n",
    "functions_pids_dict, functions_dict, functions_toked_dict, functions_detoked_dict = \\\n",
    "        get_all_functions_detok_from_cache(\n",
    "            code_id_lang_dic, functions_pids_dict_path, functions_dict_path, \n",
    "            functions_toked_dict_path, functions_detoked_dict_path)\n",
    "# function_json_dict, function_id_lang_dic = read_function_tok_file()\n",
    "split_dict = load_split_dict()\n",
    "test_list, val_list = get_eval_list(split_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-germany",
   "metadata": {},
   "source": [
    "### XLCoST pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "infectious-wedding",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_pairs = []\n",
    "for lang1 in langs:\n",
    "    for lang2 in langs:\n",
    "        if lang2 != lang1:\n",
    "            lang_pairs.append((lang1, lang2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fatty-chemical",
   "metadata": {},
   "source": [
    "#### Select data and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ranging-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'xlcost'\n",
    "tag = \"test\"\n",
    "function_data_path = home_path + \"g4g/XLCoST_data/pair_data_notok_exec_function/\"\n",
    "data_code_dict_path = code_dict_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civilian-berry",
   "metadata": {},
   "source": [
    "#### Get original code execution performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "subjective-recovery",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_lang_dict, code_id_lang_dic = read_toked_code_dict(data_code_dict_path)\n",
    "call_dict_gold = get_call_dict_gold(lang_pairs, function_data_path, code_id_lang_dic, data_name, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separated-interval",
   "metadata": {},
   "source": [
    "#### Select model, get model predictions and do hypo filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "prerequisite-newsletter",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 5\n",
    "model_type = \"codet5\"\n",
    "exp_suffix = \"_translation_exec_function/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-gibson",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "label = \"\"\n",
    "preds_lang_dict = get_preds_lang_dict(lang_pairs, model_type, device, None, None, function_data_path, \n",
    "                                      sample_size, temperature, data_name, tag, exp_suffix, label)\n",
    "call_dict_hypo = get_call_dict_hypo(lang_pairs, preds_lang_dict, call_dict_gold, code_id_lang_dic, \n",
    "                                    model_type, data_name, tag, label)\n",
    "hypo_filtering_dict = get_hypo_filtering_dict(lang_pairs, call_dict_gold, call_dict_hypo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-spank",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eval codenet trained model\n",
    "model_type = \"plbart\"\n",
    "exp_suffix = \"_translation_exec_codenet_small_function/\"\n",
    "new_langs = [\"C++\", \"Java\", \"Python\", \"C#\", \"C\"]\n",
    "new_lang_pairs = []\n",
    "for lang1 in new_langs:\n",
    "    for lang2 in new_langs:\n",
    "        if lang2 != lang1:\n",
    "            new_lang_pairs.append((lang1, lang2))\n",
    "label = \"_exec_codenet\" #_exec_codenet_small _exec_codenet_transfer_derail\n",
    "# exp_suffix = \"_translation_transfer_codenet_exec_function/\"\n",
    "preds_lang_dict = get_preds_lang_dict(new_lang_pairs, model_type, device, None, None, function_data_path, \n",
    "                                      sample_size, temperature, data_name, tag, exp_suffix, label)\n",
    "call_dict_hypo = get_call_dict_hypo(new_lang_pairs, preds_lang_dict, call_dict_gold, code_id_lang_dic, \n",
    "                                    model_type, data_name, tag, label)\n",
    "hypo_filtering_dict = get_hypo_filtering_dict(new_lang_pairs, call_dict_gold, call_dict_hypo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "decimal-longer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C++ Java\n",
      "432 103 296 831\n",
      "C++ Python\n",
      "300 202 264 766\n",
      "C++ C#\n",
      "466 77 282 825\n",
      "C++ C\n",
      "20 10 10 40\n",
      "Java C++\n",
      "386 98 347 831\n",
      "Java Python\n",
      "307 193 279 779\n",
      "Java C#\n",
      "547 37 258 842\n",
      "Java C\n",
      "16 8 15 39\n",
      "Python C++\n",
      "322 148 296 766\n",
      "Python Java\n",
      "373 113 293 779\n",
      "Python C#\n",
      "429 100 252 781\n",
      "Python C\n",
      "4 17 10 31\n",
      "C# C++\n",
      "418 106 301 825\n",
      "C# Java\n",
      "580 39 223 842\n",
      "C# Python\n",
      "321 234 226 781\n",
      "C# C\n",
      "18 10 12 40\n",
      "C C++\n",
      "32 3 5 40\n",
      "C Java\n",
      "22 6 11 39\n",
      "C Python\n",
      "7 15 9 31\n",
      "C C#\n",
      "25 5 10 40\n"
     ]
    }
   ],
   "source": [
    "# Eval codenet trained model\n",
    "model_type = \"plbart\"\n",
    "exp_suffix = \"_translation_exec_codenet_function/\"\n",
    "new_langs = [\"C++\", \"Java\", \"Python\", \"C#\", \"C\"]\n",
    "new_lang_pairs = []\n",
    "for lang1 in new_langs:\n",
    "    for lang2 in new_langs:\n",
    "        if lang2 != lang1:\n",
    "            new_lang_pairs.append((lang1, lang2))\n",
    "label = \"_exec_codenet\" #_exec_codenet_small _exec_codenet_transfer_derail\n",
    "# exp_suffix = \"_translation_transfer_codenet_exec_function/\"\n",
    "preds_lang_dict = get_preds_lang_dict(new_lang_pairs, model_type, device, None, None, function_data_path, \n",
    "                                      sample_size, temperature, data_name, tag, exp_suffix, label)\n",
    "call_dict_hypo = get_call_dict_hypo(new_lang_pairs, preds_lang_dict, call_dict_gold, code_id_lang_dic, \n",
    "                                    model_type, data_name, tag, label)\n",
    "hypo_filtering_dict = get_hypo_filtering_dict(new_lang_pairs, call_dict_gold, call_dict_hypo)\n",
    "exec_rate_dict1 = get_exec_rate_dict(hypo_filtering_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-coaching",
   "metadata": {},
   "source": [
    "#### Eval codex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "graphic-monitoring",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 91/451 [00:00<00:00, 907.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java Python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 451/451 [00:00<00:00, 740.98it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b750772946894607b45a739c2b905bba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=451.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 31/138 [00:00<00:00, 302.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python error 314 0.6962305986696231\n",
      "Python timeout 1 0.0022172949002217295\n",
      "Python empty 4 0.008869179600886918\n",
      "Python other 0 0.0\n",
      "Python good 132 0.2926829268292683\n",
      "Python Java\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 138/138 [00:00<00:00, 345.18it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f140f78e270454a84823bfae1086308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=138.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 53/189 [00:00<00:00, 525.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java error 74 0.5362318840579711\n",
      "Java timeout 0 0.0\n",
      "Java empty 0 0.0\n",
      "Java other 0 0.0\n",
      "Java good 64 0.463768115942029\n",
      "C++ Python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 189/189 [00:00<00:00, 458.19it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ff1fe27da245e0b70494b63e6bcbf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=189.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 21/144 [00:00<00:00, 196.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python error 96 0.5079365079365079\n",
      "Python timeout 1 0.005291005291005291\n",
      "Python empty 2 0.010582010582010581\n",
      "Python other 0 0.0\n",
      "Python good 90 0.47619047619047616\n",
      "Python C++\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:00<00:00, 336.00it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c8093b82084f77aa8115f94dae07fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=144.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28/28 [00:00<00:00, 626.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C++ error 87 0.6041666666666666\n",
      "C++ timeout 0 0.0\n",
      "C++ empty 0 0.0\n",
      "C++ other 0 0.0\n",
      "C++ good 57 0.3958333333333333\n",
      "C Python\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f60ba9ee26c40fb8fe224a231dc0cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=28.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 455.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python error 12 0.42857142857142855\n",
      "Python timeout 0 0.0\n",
      "Python empty 0 0.0\n",
      "Python other 0 0.0\n",
      "Python good 16 0.5714285714285714\n",
      "Python C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7030c09cd52d46688b2ab4b62d3421be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=31.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 23/130 [00:00<00:00, 217.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C error 10 0.3225806451612903\n",
      "C timeout 0 0.0\n",
      "C empty 0 0.0\n",
      "C other 0 0.0\n",
      "C good 21 0.6774193548387096\n",
      "Java C#\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:00<00:00, 261.17it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e714d38225041b7af7effe0a78ed0e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=130.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 19/83 [00:00<00:00, 183.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C# error 68 0.5230769230769231\n",
      "C# timeout 0 0.0\n",
      "C# empty 0 0.0\n",
      "C# other 0 0.0\n",
      "C# good 62 0.47692307692307695\n",
      "C# Java\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:00<00:00, 287.53it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe67e62531c4c638acf6883bd7b4382",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=83.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 479.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java error 21 0.25301204819277107\n",
      "Java timeout 0 0.0\n",
      "Java empty 0 0.0\n",
      "Java other 0 0.0\n",
      "Java good 62 0.7469879518072289\n",
      "C++ C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac767aac7c8d4a898bdf44645e2f6413",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:00<00:00, 458.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C error 9 0.23076923076923078\n",
      "C timeout 0 0.0\n",
      "C empty 0 0.0\n",
      "C other 0 0.0\n",
      "C good 30 0.7692307692307693\n",
      "Java C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc60843732d8406bbf312fd6997263d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=39.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C error 8 0.20512820512820512\n",
      "C timeout 0 0.0\n",
      "C empty 0 0.0\n",
      "C other 0 0.0\n",
      "C good 31 0.7948717948717948\n",
      "Java Python\n",
      "314 46 91 451\n",
      "Python Java\n",
      "74 5 59 138\n",
      "C++ Python\n",
      "96 32 61 189\n",
      "Python C++\n",
      "87 9 48 144\n",
      "C Python\n",
      "12 6 10 28\n",
      "Python C\n",
      "10 2 19 31\n",
      "Java C#\n",
      "68 0 62 130\n",
      "C# Java\n",
      "21 4 58 83\n",
      "C++ C\n",
      "9 3 27 39\n",
      "Java C\n",
      "8 2 29 39\n"
     ]
    }
   ],
   "source": [
    "model_type = \"codex\"\n",
    "label = \"\"\n",
    "with open(cached_path + 'merged_filtered_codex_dict.pkl', 'rb') as infile:\n",
    "    merged_filtered_codex_dict = pickle.load(infile)\n",
    "codex_preds_lang_dict, codex_pids_dict = get_preds_lang_dict_codex(merged_filtered_codex_dict, call_dict_gold)\n",
    "lang_pairs = list(codex_preds_lang_dict.keys())\n",
    "call_dict_hypo = get_call_dict_hypo_codex(lang_pairs, codex_preds_lang_dict, codex_pids_dict, \n",
    "                                    call_dict_gold, code_id_lang_dic, \n",
    "                                    model_type, data_name, tag, label)\n",
    "hypo_filtering_dict = get_hypo_filtering_dict_pids(lang_pairs, call_dict_gold, call_dict_hypo, codex_pids_dict)\n",
    "exec_rate_dict = get_exec_rate_dict(hypo_filtering_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "elect-medline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java Python\n",
      "209 121 121 451\n",
      "Python Java\n",
      "70 28 40 138\n",
      "C++ Python\n",
      "109 42 38 189\n",
      "Python C++\n",
      "90 20 34 144\n",
      "C Python\n",
      "8 14 6 28\n",
      "Python C\n",
      "10 15 6 31\n",
      "Java C#\n",
      "128 0 2 130\n",
      "C# Java\n",
      "83 0 0 83\n",
      "C++ C\n",
      "21 10 8 39\n",
      "Java C\n",
      "19 6 14 39\n"
     ]
    }
   ],
   "source": [
    "model_type = \"plbart\"\n",
    "exp_suffix = \"_translation_exec_codenet_small_function/\"\n",
    "label =\"_exec_codenet_small\"\n",
    "# lang_pairs = list(codex_preds_lang_dict.keys())\n",
    "preds_lang_dict = get_preds_lang_dict(lang_pairs, model_type, device, None, None, function_data_path, \n",
    "                                      sample_size, temperature, data_name, tag, exp_suffix, label)\n",
    "call_dict_hypo = get_call_dict_hypo(new_lang_pairs, preds_lang_dict, call_dict_gold, code_id_lang_dic, \n",
    "                                    model_type, data_name, tag, label)\n",
    "hypo_filtering_dict = get_hypo_filtering_dict_pids(lang_pairs, call_dict_gold, call_dict_hypo, codex_pids_dict)\n",
    "exec_rate_dict_pcn_small = get_exec_rate_dict(hypo_filtering_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "experienced-pulse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Java Python\n",
      "184 106 161 451\n",
      "Python Java\n",
      "75 15 48 138\n",
      "C++ Python\n",
      "85 45 59 189\n",
      "Python C++\n",
      "60 29 55 144\n",
      "C Python\n",
      "7 13 8 28\n",
      "Python C\n",
      "4 17 10 31\n",
      "Java C#\n",
      "88 5 37 130\n",
      "C# Java\n",
      "67 3 13 83\n",
      "C++ C\n",
      "20 10 9 39\n",
      "Java C\n",
      "16 8 15 39\n"
     ]
    }
   ],
   "source": [
    "model_type = \"plbart\"\n",
    "# exp_suffix = \"_translation_exec_codenet_small_function/\"\n",
    "# label =\"_exec_codenet_small\"\n",
    "exp_suffix = \"_translation_exec_codenet_function/\"\n",
    "label =\"_exec_codenet\" \n",
    "\n",
    "# lang_pairs = list(codex_preds_lang_dict.keys())\n",
    "preds_lang_dict = get_preds_lang_dict(lang_pairs, model_type, device, None, None, function_data_path, \n",
    "                                      sample_size, temperature, data_name, tag, exp_suffix, label)\n",
    "call_dict_hypo = get_call_dict_hypo(new_lang_pairs, preds_lang_dict, call_dict_gold, code_id_lang_dic, \n",
    "                                    model_type, data_name, tag, label)\n",
    "hypo_filtering_dict = get_hypo_filtering_dict_pids(lang_pairs, call_dict_gold, call_dict_hypo, codex_pids_dict)\n",
    "exec_rate_dict_pcn = get_exec_rate_dict(hypo_filtering_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-cutting",
   "metadata": {},
   "source": [
    "#### Get execution rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "sublime-spyware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\t\\t32.28\\t\\t69.23\\t\n",
      "\\t\\t20.18\\t47.69\\t74.36\\t\n",
      "33.33\\t42.75\\t\\t\\t61.29\\t\n",
      "\\t69.88\\t\\t\\t\\t\n",
      "\\t\\t35.71\\t\\t\\t\n"
     ]
    }
   ],
   "source": [
    "print_exec_results(exec_rate_dict, new_langs=new_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "caring-julian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\t35.62\\t34.46\\t34.18\\t25.0\\t\n",
      "41.76\\t\\t35.82\\t30.64\\t38.46\\t\n",
      "38.64\\t37.61\\t\\t32.27\\t32.26\\t\n",
      "36.48\\t26.48\\t28.94\\t\\t30.0\\t\n",
      "12.5\\t28.21\\t29.03\\t25.0\\t\\t\n"
     ]
    }
   ],
   "source": [
    "print_exec_results(exec_rate_dict1, new_langs=new_langs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "fleet-trustee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\t\\t31.22\\t\\t23.08\\t\n",
      "\\t\\t35.7\\t28.46\\t38.46\\t\n",
      "38.19\\t34.78\\t\\t\\t32.26\\t\n",
      "\\t15.66\\t\\t\\t\\t\n",
      "\\t\\t28.57\\t\\t\\t\n"
     ]
    }
   ],
   "source": [
    "# exec_rate_dict\n",
    "from sample_utils import *\n",
    "print_exec_results(exec_rate_dict_pcn, new_langs=new_langs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-forum",
   "metadata": {},
   "source": [
    "#### Eval new experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-outline",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_suffix = \"_translation_exec_codenet_function/\"\n",
    "lang_pairs = [('Java', \"Python\"), ('Python', \"Java\"), ('Java', \"C#\"), ('C#', \"Java\")]\n",
    "preds_lang_dict = get_preds_lang_dict(lang_pairs, model_type, device, None, None, function_data_path, \n",
    "                                      sample_size, temperature, data_name, tag, exp_suffix, label=\"haha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "talented-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Golden results are in result_id_dict_gold\n",
    "(map_dict, reverse_map_dict), pids, programs_gold, \\\n",
    "(result_id_dict_gold,  result_key_dict_gold, error_type_dict_gold) = call_dict_gold[(lang1, lang2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "impaired-circle",
   "metadata": {},
   "outputs": [],
   "source": [
    "# passed_hypo_dict contains hypo that matches the output of golden.\n",
    "lang1 = \"Java\"\n",
    "lang2 = \"Python\"\n",
    "preds = preds_lang_dict[(lang1, lang2)]\n",
    "pids, programs, program_id_dict, program_dict, (result_id_dict, result_key_dict, error_type_dict)\\\n",
    "    = call_dict_hypo[(lang1, lang2)]\n",
    "buggy_pids, failed_test_pids, passed_hypo_dict = hypo_filtering_dict[(lang1, lang2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "violent-sydney",
   "metadata": {},
   "source": [
    "#### Repeated sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "silver-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 2\n",
    "is_eval = True\n",
    "repeated_sampling_dict = get_repeated_sampling_dict(lang_pairs, model_type, device, \n",
    "                                         None, None, function_data_path, code_id_lang_dic, \n",
    "                                         data_name, 'val', exp_suffix, \n",
    "                                         is_eval, num_iterations, sample_size, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "instructional-sequence",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cached_path + \"plbart_test_xlcost_repeated_sampling_dict.pkl\", 'wb') as outfile:\n",
    "    pickle.dump(repeated_sampling_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "moral-restoration",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cached_path + \"plbart_test_xlcost_repeated_sampling_dict.pkl\", 'rb') as infile:\n",
    "    repeated_sampling_dict = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dirty-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang1 = \"Java\"\n",
    "lang2 = \"Python\"\n",
    "buggy_pids, failed_test_pids, good_hypo_dict = repeated_sampling_dict[(lang1, lang2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "competent-sweet",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164 188 427\n"
     ]
    }
   ],
   "source": [
    "print(len(buggy_pids), len(failed_test_pids), len(good_hypo_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "interstate-radius",
   "metadata": {},
   "source": [
    "### Leetcode Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convertible-senegal",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_pairs = []\n",
    "for lang1 in tri_langs:\n",
    "    for lang2 in tri_langs:\n",
    "        if lang2 != lang1:\n",
    "            lang_pairs.append((lang1, lang2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "varying-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'leetcode'\n",
    "function_data_path = leetcode_pair_data_path + \"pair_data_notok_exec_leetcode/\"\n",
    "data_code_dict_path = leetcode_code_dict_path\n",
    "code_lang_dict, code_id_lang_dic = read_toked_code_dict(data_code_dict_path, tri_langs)\n",
    "# leetcode has to be evaluated on testcases.\n",
    "# call_dict_gold = get_call_dict_gold(lang_pairs, function_data_path, code_id_lang_dic, data_name, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "invisible-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = {}\n",
    "call_dict = {}\n",
    "for lang in tri_langs:\n",
    "    print(lang)\n",
    "    programs, program_id_dict, pids = prepare_exec_program(code_id_lang_dic, lang)\n",
    "    call_dict[lang] = programs, program_id_dict, pids\n",
    "    print(len(programs))\n",
    "    lang_results = p_map(file_executors[lang], programs)\n",
    "    results_dict[lang] = lang_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eleven-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leetcode pairwise is only a small part of leetcode. The rest of it is unaligned.\n",
    "# try to get the single pids in eahc lang\n",
    "leetcode_split_dict = get_leetcode_split(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "turned-fellow",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mingzhu/CodeModel/CodeGen_cwd/cached_files/plbart_test_xlcost_call_dict_hypo.pkl\n"
     ]
    }
   ],
   "source": [
    "sample_size = 5\n",
    "model_type = \"plbart\"\n",
    "exp_suffix = \"translation_leetcode_exec_function/\" #translation_transfer_leetcode_exec_function\n",
    "preds_lang_dict = get_preds_lang_dict(lang_pairs, model_type, device, function_data_path, \n",
    "                                      data_name, tag, exp_suffix)\n",
    "call_dict_hypo = get_call_dict_hypo(lang_pairs, preds_lang_dict, call_dict_gold, code_id_lang_dic, \n",
    "                                    model_type, data_name, tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "radical-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cached_path + \"plbart_xlcost_call_dict_hypo.pkl\", 'wb') as outfile:\n",
    "    pickle.dump(call_dict_hypo, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypo_filtering_dict = get_hypo_filtering_dict(lang_pairs, call_dict_gold, call_dict_hypo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "express-address",
   "metadata": {},
   "source": [
    "### Pipeline for single language pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nutritional-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = 'xlcost'\n",
    "tag = \"test\"\n",
    "function_data_path = home_path + \"g4g/XLCoST_data/pair_data_notok_exec_function/\"\n",
    "data_code_dict_path = code_dict_path\n",
    "lang1 = \"Java\"\n",
    "lang2 = \"C#\" \n",
    "code_lang_dict, code_id_lang_dic = read_toked_code_dict(data_code_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "civilian-pledge",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"plbart\"\n",
    "model, tokenizer, decoder_sid = get_model_by_name(model_type, device, lang1, lang2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "specialized-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file, args = prep_eval_args(model_type, tokenizer, lang1, lang2, function_data_path)\n",
    "args.eval_batch_size = 32\n",
    "eval_examples, eval_features = get_eval_examples_from_file(test_file, tokenizer, args)\n",
    "eval_dataloader = get_eval_dataloader(eval_features, args.eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "twenty-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_string = \"static int minSum ( int A [ ] , int N ) { HashMap < Integer , Integer > mp = new HashMap < Integer , Integer > ( ) ; int sum = 0 ; for ( int i = 0 ; i < N ; i ++ ) { sum += A [ i ] ; if ( mp . containsKey ( A [ i ] ) ) { mp . put ( A [ i ] , mp . get ( A [ i ] ) + 1 ) ; } else { mp . put ( A [ i ] , 1 ) ; } } int minSum = Integer . MAX_VALUE ; for ( Map . Entry < Integer , Integer > it : mp . entrySet ( ) ) { minSum = Math . min ( minSum , sum - ( it . getKey ( ) * it . getValue ( ) ) ) ; } return minSum ; }\"\n",
    "batch = get_eval_tensors(code_string, tokenizer, args)\n",
    "pred = get_generation_demo(batch, model, tokenizer, args, device, False, decoder_sid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "defensive-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spiritual-struggle",
   "metadata": {},
   "source": [
    "### Beam search (or greedy decoding) with single return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swedish-scanner",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_sample = False\n",
    "preds, dev_bleu, xmatch = generation_single(eval_examples, eval_dataloader, \n",
    "                                            model, tokenizer, args, device, \n",
    "                                            do_sample, temperature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "generous-booth",
   "metadata": {},
   "source": [
    "### Sampling with single return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "former-sight",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:36<00:00,  4.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  bleu-4 = 71.13 \n",
      "  xMatch = 7.0312 \n",
      "  ********************\n"
     ]
    }
   ],
   "source": [
    "do_sample = True\n",
    "preds, dev_bleu, xmatch = generation_single(eval_examples, eval_dataloader, \n",
    "                                            model, tokenizer, args, device, \n",
    "                                            do_sample, temperature, )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "double-sight",
   "metadata": {},
   "source": [
    "### Sampling with multiple return sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-yellow",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, accs, dev_bleus, dev_bleu, xmatch = generation_multiple(eval_examples, eval_dataloader, \n",
    "                                                             model, tokenizer, args, device, \n",
    "                                                             decoder_sid, 5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "asian-third",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 5\n",
    "out_fn = get_out_fn(True, temperature, args.beam_size)\n",
    "preds = get_sample_generations(eval_dataloader, model, tokenizer, args, device, \n",
    "                               decoder_sid, num_samples, temperature)\n",
    "accs, dev_bleus, dev_bleu, xmatch = eval_bleu_samples(eval_examples, args, preds, out_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "meaning-comfort",
   "metadata": {},
   "source": [
    "#### Try sampling on codebert (failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "marked-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypos=[]\n",
    "pred_ids = []\n",
    "for batch in tqdm(eval_dataloader,total=len(eval_dataloader)):\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    source_ids,source_mask= batch                  \n",
    "    with torch.no_grad():\n",
    "        preds = model(source_ids=source_ids, source_mask=source_mask, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dominant-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from run import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "attached-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang1 = \"Java\"\n",
    "lang2 = \"Python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "interior-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_type = \"codebert\"\n",
    "model_name_or_path = model_name_dict[model_type]\n",
    "model_path = func_model_path + model_type + \"/\" + model_type + exp_suffix\n",
    "load_model_path_prefix = model_path + lang1 + \"-\" + lang2 + '/'\n",
    "load_model_path = load_model_path_prefix + \"checkpoint-best-bleu/pytorch_model.bin\"\n",
    "config_class, model_class, tokenizer_class = MODEL_CLASSES[model_type]\n",
    "config = config_class.from_pretrained(model_name_or_path)\n",
    "tokenizer = tokenizer_class.from_pretrained(model_name_or_path)\n",
    "decoder_sid = tokenizer.eos_token_id\n",
    "if model_type == \"codebert\":\n",
    "    encoder = model_class.from_pretrained(model_name_or_path)    \n",
    "    decoder_layer = nn.TransformerDecoderLayer(d_model=config.hidden_size, nhead=config.num_attention_heads)\n",
    "    decoder = nn.TransformerDecoder(decoder_layer, num_layers=6)\n",
    "    model=Seq2Seq(encoder=encoder,decoder=decoder,config=config,\n",
    "                  sos_id=tokenizer.cls_token_id,eos_id=tokenizer.sep_token_id)\n",
    "else:\n",
    "    model = model_class.from_pretrained(model_name_or_path)\n",
    "if model_type != \"plbart\":\n",
    "    decoder_sid = None\n",
    "model.load_state_dict(torch.load(load_model_path))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "developed-canvas",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.model_type = 'roberta'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "comparative-estonia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get preds_lang_dict for codebert\n",
    "model_type = \"codet5\"\n",
    "model_path = func_model_path + model_type + \"/\" + model_type + exp_suffix\n",
    "preds_lang_dict = {}\n",
    "for lang1, lang2 in lang_pairs:\n",
    "    lang_pair_path = model_path + lang1 + \"-\" + lang2 + '/'\n",
    "    hypo_path = lang_pair_path + \"test_0.output\"\n",
    "    with open(hypo_path) as infile:\n",
    "        lines = infile.readlines()\n",
    "    preds = [[x.strip()] for x in lines]\n",
    "    preds_lang_dict[(lang1, lang2)] = preds\n",
    "label = \"beam\"\n",
    "preds_lang_dict_path = \\\n",
    "    cached_path + model_type + \"_\" + tag + \"_\" + data_name + \"_preds_lang_dict\" + label + \".pkl\"\n",
    "with open(preds_lang_dict_path, 'wb') as outfile:\n",
    "    pickle.dump(preds_lang_dict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extensive-education",
   "metadata": {},
   "source": [
    "### Check compilation rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "compact-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_dict, reverse_map_dict = get_target_map_dict(lang1, lang2, function_data_path)\n",
    "pids = [map_dict[x] for x in range(len(map_dict))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "dirty-kidney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41233b5e060d44d7b395d80d19b5f39c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=842.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C# error 0 0.0\n",
      "C# timeout 0 0.0\n",
      "C# empty 0 0.0\n",
      "C# other 0 0.0\n",
      "C# good 842 1.0\n"
     ]
    }
   ],
   "source": [
    "programs_gold, lang_results_gold, result_dicts = exec_gold(map_dict, lang2, code_id_lang_dic)\n",
    "result_id_dict_gold, result_key_dict_gold, error_type_dict_gold = result_dicts\n",
    "error_type_dict_gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "focal-deputy",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 842/842 [00:11<00:00, 74.61it/s]\n"
     ]
    }
   ],
   "source": [
    "programs, program_id_dict, program_dict = prep_exec_hypo(preds, pids, code_id_lang_dic, lang2, model_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "heard-nitrogen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a699e896859e46438c5cc7447cf18640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4210.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lang_results = p_map(file_executors[lang2], programs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proof-district",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = {lang2:lang_results}\n",
    "result_type_dict = show_result_summary(result_dict)\n",
    "result_id_dict, result_key_dict, error_type_dict = result_mapping(lang_results, program_id_dict, pids, lang2)\n",
    "print(error_type_dict)\n",
    "buggy_pids, failed_test_pids, passed_hypo_dict = hypo_filtering(result_id_dict, \n",
    "                                                                result_id_dict_gold, \n",
    "                                                                result_key_dict, \n",
    "                                                                program_dict)\n",
    "print(len(buggy_pids),len(failed_test_pids), len(passed_hypo_dict), len(pids))\n",
    "fail_pids = buggy_pids + failed_test_pids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coated-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = file_executors[lang2](b)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-physiology",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_src(\"\".join(code_id_lang_dic['Java']['3096']['program_pieces']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unknown-evanescence",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = detok_format(program_dict['3096'][1], file_detokenizers[lang2])\n",
    "print_src(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modular-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, result_keys in result_key_dict.items():\n",
    "    for i, key in enumerate(result_keys):\n",
    "        if key == \"error\":\n",
    "            error = result_id_dict[idx][i]\n",
    "            if \"a function-definition is not allowed\" in error:\n",
    "                print(idx, i, error)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romance-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 312 572 209 363 884 sample_size=1 plbart temper=0.5\n",
    "# 227 657 247 410 884 sample_size=5 plbart temper=0.5\n",
    "# 196 688 256 432 884 sample_size=10 plbart temper=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mighty-elizabeth",
   "metadata": {},
   "outputs": [],
   "source": [
    "buggy_pids, failed_test_pids, passed_hypo_dict = sampling_filtering(pids, eval_examples, eval_features, \n",
    "                     function_id_lang_dic, reverse_map_dict, lang,\n",
    "                    model, tokenizer, args, device, decoder_sid, 10, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-capital",
   "metadata": {},
   "outputs": [],
   "source": [
    "buggy_pids, failed_test_pids, good_hypo_dict = repeated_sampling(pids, eval_examples, eval_features, \n",
    "                                                     function_id_lang_dic, reverse_map_dict, lang,\n",
    "                                                     model, tokenizer, args, device, decoder_sid, \n",
    "                                                     5, temperature, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exterior-seafood",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_src(passed_hypo_dict['7390'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-freeze",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_src(function_id_lang_dic[lang2]['7390']['program_formatted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-deposit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter out output that's binary (this is why multiple testcase is needed)\n",
    "# channel in more data from other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlike-preview",
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = '1535'\n",
    "# function_id_lang_dic[lang2][key]['code_dict']\n",
    "key = 2\n",
    "print_src(program_dict[pid][key])\n",
    "print(result_id_dict[pid][key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "coral-instruction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 def reversed ( string ) :\n",
      "2     if string == None or ( len ( string ) <= 1 ) :\n",
      "3         print string\n",
      "4     else :\n",
      "5         print string [ len ( string ) - 1 ]\n",
      "6         string = string [ : len ( string ) - 1 ]\n",
      "7         string [ len ( string ) - 1 ] = string [ len ( string ) - 1 ]\n",
      "8 \n",
      "9 string = \"Geeks for Geeks\"\n",
      "10 reverse(string)\n"
     ]
    }
   ],
   "source": [
    "program = \"\".join(function_id_lang_dic[lang2][pid]['code_dict']['program_pieces']).replace(\n",
    "    target_function_place_holder, program_dict[pid][key])\n",
    "print_src(program)\n",
    "b = run_exec_python(program)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
