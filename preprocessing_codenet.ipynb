{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "healthy-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "instant-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./huggingface_models/')\n",
    "sys.path.append('./utils/')\n",
    "from sample_utils import *\n",
    "from inference_utils import *\n",
    "from codenet_process_utils import *\n",
    "from self_training_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "conditional-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "micro-celtic",
   "metadata": {},
   "source": [
    "### Remove solutions that are in other languages\n",
    "See the botton cell.\n",
    "\n",
    "### Collect accepted problems\n",
    "Get problems_dict: get_codenet_dict\n",
    "```\n",
    "problems_dict['p00001'].keys(): ['desc', 'io', 'solutions']\n",
    "```\n",
    "Rare problems have 'meta' also.\n",
    "```\n",
    "problems_dict['p00001']['io'].keys(): ['output', 'input']\n",
    "```\n",
    "The 'io' seems to be extracted from the 'desc', but not exhaustively. The 'desc' usually contains more input-output pairs than what's in 'io'.\n",
    "\n",
    "### Parse the programs into codedict\n",
    "Get code_dict: get_codenet_code_dict\n",
    "```\n",
    "codes_dict['p00001'].keys(): ['C++', 'Java', 'Python', 'C#', 'C']\n",
    "codes_dict['Java'][0].keys(): ['functions', 'program_pieces', 'function_names', 'parameter_lists', 'return_types', 'target_call', 'target_call_args', 'target_call_params', 'target_call_return_type', 'idx', 'pid', 'program_formatted', 'io']\n",
    "codes_dict['Java'][0]['idx']:'s150444541.java'\n",
    "codes_dict['Java'][0]['pid']:'p00100'\n",
    "```\n",
    "\n",
    "### Filter programs by function and compilation\n",
    "1. Filter programs that has functions (other than main/Main): get_nonempty_functions\n",
    "2. Filter by compilation: get_codenet_call_dict. Note that in this step, we don't compile the original program. Instead, we combine the import_str extracted from the original program with the functions into a new program, and compile this new program.\n",
    "3. Get filtered programs: get_compiled_functions\n",
    "We get call_dict in this step. \\\n",
    "```\n",
    "call_dict[lang] = [programs, processed_results, result_keys, error_type_dict]\n",
    "```\n",
    "We also get filtered_dict in this step.\\\n",
    "```\n",
    "filtered_dict[\"Java\"][0].keys(): ['code_dic_id', \"import_str\", \"function\", \"pid\"]\n",
    "```\n",
    "\n",
    "### Merge filtered program\n",
    "Merge all the filtered programs into one dict (merged_filtered_dict).\n",
    "```\n",
    "merged_filtered_dict.keys(): ['C++', 'Java', 'Python', 'C#', 'C']\n",
    "merged_filtered_dict[\"Java\"][0].keys(): ['code_dic_id', 'import_str', 'function', 'pid', 'code_dic', 'batch_id']\n",
    "```\n",
    "\n",
    "### No-tok preprocessing\n",
    "Process the filtered data for model training.\n",
    "1. remove comments, empty lines format_codestring_codenet(codestring, lang)\n",
    "2. replace new_lines notok_prepro(codestring, lang, is_plbart)\n",
    "3. after decoding, do notok_detok notok_detok(codestring, lang, is_plbart)\n",
    "4. do detok_format(codestring, detokenizer) to get detokenized version for Java and Python\n",
    "\n",
    "### Cached Files\n",
    "codenet/codenet_problems_dict_i.json\\\n",
    "codenet/codenet_codedict_i.json\\\n",
    "codenet/codenet_call_dict_i.json\\\n",
    "codenet/codenet_filtered_dict_i.json\\\n",
    "codenet_merged_filtered_dict.json\n",
    "codenet_merged_filtered_dict_notok.json\\\n",
    "\n",
    "Since \"java\" is a special token in plbart, we have to create input data for plbart separately.\\\n",
    "codenet_merged_filtered_dict_notok_plbart.json\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-noise",
   "metadata": {},
   "source": [
    "### Codenet data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "piano-queensland",
   "metadata": {},
   "source": [
    "#### Get codedicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-highland",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batch = 41\n",
    "code_lang_dict_list = []\n",
    "for i in tqdm(range(num_batch)):\n",
    "    print(i)\n",
    "    codedict_path = cached_path + 'codenet/codenet_codedict_' + str(i) + '.json'\n",
    "    if os.path.exists(codedict_path):\n",
    "        continue\n",
    "    with open(cached_path + 'codenet/codenet_problems_dict_' + str(i) + '.json') as infile:\n",
    "        codenet_problems_dict_batch = json.load(infile)\n",
    "    programs_dict, programs_idx_dict, program_id_dict = get_codenet_programs(\n",
    "                                                            codenet_problems_dict_batch, new_langs)\n",
    "    code_lang_dict = get_codenet_code_dict(programs_dict, programs_idx_dict, program_id_dict, \n",
    "                                       codenet_problems_dict_batch)\n",
    "    with open(cached_path + 'codenet/codenet_codedict_' + str(i) + '.json', 'w') as outfile:\n",
    "        json.dump(code_lang_dict, outfile)\n",
    "    code_lang_dict_list.append(code_lang_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-pressure",
   "metadata": {},
   "source": [
    "#### Filter out programs that compiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greatest-disability",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batch = 41\n",
    "todo_idx = [i for i in range(num_batch)]\n",
    "for i in todo_idx:\n",
    "    print(i)\n",
    "    codedict_path = cached_path + 'codenet/codenet_codedict_' + str(i) + '.json'\n",
    "    if os.path.exists(codedict_path):\n",
    "        with open(codedict_path) as infile:\n",
    "            code_lang_dict = json.load(infile)\n",
    "    func_id_dict, program_dict, imports_dict = get_nonempty_functions(code_lang_dict, new_langs)\n",
    "    call_dict = get_codenet_call_dict(program_dict, imports_dict, new_langs)\n",
    "    filtered_dict = get_compiled_functions(call_dict, func_id_dict, imports_dict, program_dict, \n",
    "                                       code_lang_dict)\n",
    "    call_dict_path = cached_path + 'codenet/codenet_call_dict_' + str(i) + '.json'\n",
    "    with open(call_dict_path, 'w') as outfile:\n",
    "        json.dump(call_dict, outfile)\n",
    "    filtered_dict_path = cached_path + 'codenet/codenet_filtered_dict_' + str(i) + '.json'\n",
    "    with open(filtered_dict_path, 'w') as outfile:\n",
    "        json.dump(filtered_dict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-conviction",
   "metadata": {},
   "source": [
    "#### Merge into one dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relative-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "codedict_list = []\n",
    "call_dict_list = []\n",
    "filtered_dict_list = []\n",
    "for i in range(41):\n",
    "    codedict_path = cached_path + 'codenet/codenet_codedict_' + str(i) + '.json'\n",
    "    call_dict_path = cached_path + 'codenet/codenet_call_dict_' + str(i) + '.json'\n",
    "    filtered_dict_path = cached_path + 'codenet/codenet_filtered_dict_' + str(i) + '.json'\n",
    "    with open(codedict_path) as infile:\n",
    "        codedict = json.load(infile)\n",
    "    with open(call_dict_path) as infile:\n",
    "        call_dict = json.load(infile)\n",
    "    with open(filtered_dict_path) as infile:\n",
    "        filtered_dict = json.load(infile)\n",
    "    codedict_list.append(codedict)\n",
    "    call_dict_list.append(call_dict)\n",
    "    filtered_dict_list.append(filtered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "radio-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_filtered_dict = {x:[] for x in new_langs}\n",
    "for i, filtered_dict in tqdm(enumerate(filtered_dict_list)):\n",
    "    code_lang_dict = codedict_list[i]\n",
    "    for lang in new_langs:\n",
    "        for fd in filtered_dict[lang]:\n",
    "            fd['code_dic'] = code_lang_dict[lang][fd['code_dic_id']]\n",
    "            fd['batch_id'] = i\n",
    "        merged_filtered_dict[lang] += filtered_dict[lang]\n",
    "for lang in new_langs:\n",
    "    print(lang, len(merged_filtered_dict[lang]))\n",
    "with open(cached_path + 'codenet_merged_filtered_dict_full.json', 'w') as outfile:\n",
    "    json.dump(merged_filtered_dict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noble-ticket",
   "metadata": {},
   "source": [
    "### No-tok preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "successful-elimination",
   "metadata": {},
   "source": [
    "#### No Tokenization Processing Steps:\n",
    "1. remove comments, empty lines format_codestring_codenet(codestring, lang)\n",
    "2. replace new_lines notok_prepro(codestring, lang, is_plbart)\n",
    "3. after decoding, do notok_detok notok_detok(codestring, lang, is_plbart)\n",
    "4. do detok_format(codestring, detokenizer) to get detokenized version for Java and Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vital-trailer",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_plbart = True\n",
    "merged_filtered_dict = get_prepro_filtered_dict(merged_filtered_dict, is_plbart)\n",
    "dic_path = cached_path + \"codenet_merged_filtered_dict_notok_plbart.json\"\n",
    "with open(dic_path, 'w') as outfile:\n",
    "    json.dump(merged_filtered_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "swiss-bedroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_plbart = False\n",
    "merged_filtered_dict = get_prepro_filtered_dict(merged_filtered_dict, is_plbart)\n",
    "dic_path = cached_path + \"codenet_merged_filtered_dict_notok.json\"\n",
    "with open(dic_path, 'w') as outfile:\n",
    "    json.dump(merged_filtered_dict, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-failure",
   "metadata": {},
   "source": [
    "### Get input stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interior-commissioner",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_batch = 41\n",
    "code_lang_dict_list = []\n",
    "len_dict = {}\n",
    "for i in tqdm(range(num_batch)):\n",
    "    codedict_path = cached_path + 'codenet/codenet_codedict_' + str(i) + '.json'\n",
    "    if os.path.exists(codedict_path):\n",
    "        with open(cached_path + 'codenet/codenet_problems_dict_' + str(i) + '.json') as infile:\n",
    "            codenet_problems_dict_batch = json.load(infile)\n",
    "        programs_dict, programs_idx_dict, program_id_dict = get_codenet_programs(\n",
    "                                                                codenet_problems_dict_batch, new_langs)\n",
    "        len_dict[i] = {}\n",
    "        for lang in new_langs:\n",
    "            len_dict[i][lang] = len(programs_dict[lang])\n",
    "            print(lang, len(programs_dict[lang]))\n",
    "#         code_lang_dict = get_codenet_code_dict(programs_dict, programs_idx_dict, program_id_dict, \n",
    "#                                            codenet_problems_dict_batch)\n",
    "\n",
    "        with open(codedict_path) as infile:\n",
    "            code_lang_dict = json.load(infile)\n",
    "        code_lang_dict_list.append(code_lang_dict)\n",
    "#         for lang in new_langs:\n",
    "#             print(lang, len(code_lang_dict[lang]))\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acute-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_lang_dict = {x:0 for x in new_langs}\n",
    "for i, dic in len_dict.items():\n",
    "    for lang in new_langs:\n",
    "        len_lang_dict[lang] += dic[lang]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "driving-vampire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C++': 4353049, 'Java': 354982, 'Python': 1796563, 'C#': 125580, 'C': 313360}\n"
     ]
    }
   ],
   "source": [
    "# raw input programs\n",
    "print(len_lang_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ignored-australian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C++': 1927089, 'Java': 140105, 'Python': 268647, 'C#': 67692, 'C': 80661}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# programs with at least one function\n",
    "count_lang_dict = {x:0 for x in new_langs}\n",
    "for code_lang_dict in code_lang_dict_list:\n",
    "    for lang in new_langs:\n",
    "        dics = code_lang_dict[lang]\n",
    "        #TODO. Count dics have more than one func\n",
    "        for dic in dics:\n",
    "            if len(dic['functions']) > 0:\n",
    "                count_lang_dict[lang] += 1\n",
    "count_lang_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "soviet-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C++ 195942\n",
      "Java 32053\n",
      "Python 261486\n",
      "C# 17716\n",
      "C 26547\n"
     ]
    }
   ],
   "source": [
    "# programs that compiles\n",
    "is_plbart = True\n",
    "merged_filtered_dict = get_prepro_filtered_dict(None, is_plbart)\n",
    "for lang in new_langs:\n",
    "    print(lang, len(merged_filtered_dict[lang]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-coast",
   "metadata": {},
   "source": [
    "### Clean CodeNet Accepted Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optional-connection",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove langs other than the 7 langs\n",
    "fns = os.listdir(codenet_data_path)\n",
    "for fn in fns:\n",
    "    lang_path = codenet_data_path + fn + '/'\n",
    "    lang_fns = os.listdir(lang_path)\n",
    "    for lang_fn in lang_fns:\n",
    "        print(lang_fn)\n",
    "        if lang_fn not in langs:\n",
    "            shutil.rmtree(lang_path + lang_fn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
