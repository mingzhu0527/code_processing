{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "healthy-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "instant-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./huggingface_models/')\n",
    "sys.path.append('./utils/')\n",
    "from sample_utils import *\n",
    "from inference_utils import *\n",
    "from codenet_process_utils import *\n",
    "from self_training_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "conditional-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-imaging",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "### Collect accepted problems\n",
    "Get problems_dict: get_codenet_dict\n",
    "```\n",
    "problems_dict['p00001'].keys(): ['desc', 'io', 'solutions']\n",
    "```\n",
    "Rare problems have 'meta' also.\n",
    "```\n",
    "problems_dict['p00001']['io'].keys(): ['output', 'input']\n",
    "```\n",
    "The 'io' seems to be extracted from the 'desc', but not exhaustively. The 'desc' usually contains more input-output pairs than what's in 'io'.\n",
    "\n",
    "### Parse the programs into codedict\n",
    "Get code_dict: get_codenet_code_dict\n",
    "```\n",
    "codes_dict['p00001'].keys(): ['C++', 'Java', 'Python', 'C#', 'C']\n",
    "codes_dict['Java'][0].keys(): ['functions', 'program_pieces', 'function_names', 'parameter_lists', 'return_types', 'target_call', 'target_call_args', 'target_call_params', 'target_call_return_type', 'idx', 'pid', 'program_formatted', 'io']\n",
    "codes_dict['Java'][0]['idx']:'s150444541.java'\n",
    "codes_dict['Java'][0]['pid']:'p00100'\n",
    "```\n",
    "\n",
    "### Filter programs by function and compilation\n",
    "1. Filter programs that has functions (other than main/Main): get_nonempty_functions\n",
    "2. Filter by compilation: get_codenet_call_dict. Note that in this step, we don't compile the original program. Instead, we combine the import_str extracted from the original program with the functions into a new program, and compile this new program.\n",
    "3. Get filtered programs: get_compiled_functions\n",
    "We get call_dict in this step. \\\n",
    "```\n",
    "call_dict[lang] = [programs, processed_results, result_keys, error_type_dict]\n",
    "```\n",
    "We also get filtered_dict in this step.\\\n",
    "```\n",
    "filtered_dict[\"Java\"][0].keys(): ['code_dic_id', \"import_str\", \"function\", \"pid\"]\n",
    "```\n",
    "\n",
    "### Merge filtered program\n",
    "Merge all the filtered programs into one dict (merged_filtered_dict).\n",
    "```\n",
    "merged_filtered_dict.keys(): ['C++', 'Java', 'Python', 'C#', 'C']\n",
    "merged_filtered_dict[\"Java\"][0].keys(): ['code_dic_id', 'import_str', 'function', 'pid', 'code_dic', 'batch_id']\n",
    "```\n",
    "\n",
    "### No-tok preprocessing\n",
    "Process the filtered data for model training.\n",
    "1. remove comments, empty lines format_codestring_codenet(codestring, lang)\n",
    "2. replace new_lines notok_prepro(codestring, lang, is_plbart)\n",
    "3. after decoding, do notok_detok notok_detok(codestring, lang, is_plbart)\n",
    "4. do detok_format(codestring, detokenizer) to get detokenized version for Java and Python\n",
    "\n",
    "### Cached Files\n",
    "codenet/codenet_problems_dict_i.json\\\n",
    "codenet/codenet_codedict_i.json\\\n",
    "codenet/codenet_call_dict_i.json\\\n",
    "codenet/codenet_filtered_dict_i.json\\\n",
    "codenet_merged_filtered_dict.json\n",
    "codenet_merged_filtered_dict_notok.json\\\n",
    "\n",
    "Since \"java\" is a special token in plbart, we have to create input data for plbart separately.\\\n",
    "codenet_merged_filtered_dict_notok_plbart.json\\\n",
    "\n",
    "\n",
    "## Sampling:\n",
    "(Use script: get_codenet_preds.py)\n",
    "1. get preds: get_preds_lang_dict_codenet\n",
    "2. merge hypo files (since sampling takes time, we sample some languages in parallel. Thus we need to merge them later)\n",
    "\n",
    "We get preds_lang_dict in this step. \\\n",
    "preds_lang_dict[(lang1, lang2)] = preds\n",
    "\n",
    "## Filtering:\n",
    "1. remove duplicated preds: get_dedup_preds\n",
    "2. filter by type-matching: prep_exec_hypo_codenet\n",
    "3. filter by compilation: get_hypo_call_list\n",
    "\n",
    "We get hypo call_dict in this step. \\\n",
    "call_list contains info about the processed hypos in lang2.\\\n",
    "```\n",
    "call_list = [programs, processed_results, result_keys, error_type_dict]\n",
    "call_dict[(lang1, lang2)] = [new_preds, functions, function_id_dict, call_list]\n",
    "```\n",
    "\n",
    "## Hypo Processing\n",
    "1. Preprocess filtered hypos: get_lang_pair_dict\\\n",
    "    1.1 No-tok preprocessing\n",
    "2. Merge lang1-lang2 and lang2-lang1\n",
    "3. Split in to train/val/test: get_split_lang_pair_dict\n",
    "4. Write into parallel files: write_codenet_pairdata\n",
    "\n",
    "We get lang_pair_dict in this step.\\\n",
    "```\n",
    "lang_pair_list = [src_codes, target_codes, pids]\n",
    "lang_pair_dict[(lang1, lang2)] = lang_pair_list\n",
    "```\n",
    "\n",
    "### Cached Files\n",
    "1. Preds from trained models\\\n",
    "    plbart_codenet_preds_lang_dict.pkl\\\n",
    "    codet5_codenet_preds_lang_dict.pkl\n",
    "2. Hypo call_dict\\\n",
    "    plbart_codenet_lang_pair_call_dict.pkl\n",
    "3. Generated Parallel data\\\n",
    "    codet5_codenet_src_hypo_pair_dict_plbart.pkl\n",
    "4. Hypo split_dict\\\n",
    "    codenet_hypo_split_dict.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "touched-valuable",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "forced-worth",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"preprocessing_codenet.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-apache",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "proprietary-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"sampling_codenet.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graduate-reality",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "technological-configuration",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"filtering_hypo_codenet.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-present",
   "metadata": {},
   "source": [
    "### Filtered Hypo PostProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "other-scene",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"postprocessing_filtered_hypo_codenet.ipynb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painted-pledge",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "blessed-franchise",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"utils_codenet.ipynb\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
