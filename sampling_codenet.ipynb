{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "healthy-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "instant-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./huggingface_models/')\n",
    "sys.path.append('./utils/')\n",
    "from sample_utils import *\n",
    "from inference_utils import *\n",
    "from codenet_process_utils import *\n",
    "from self_training_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "conditional-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "animal-insulation",
   "metadata": {},
   "source": [
    "### Sampling:\n",
    "1. get preds: get_preds_lang_dict_codenet\n",
    "2. merge hypo files (since sampling takes time, we sample some languages in parallel. Thus we need to merge them later)\n",
    "\n",
    "We get preds_lang_dict in this step. \\\n",
    "preds_lang_dict[(lang1, lang2)] = preds\n",
    "\n",
    "\n",
    "### Cached Files\n",
    "1. Preds from trained models\\\n",
    "    plbart_codenet_preds_lang_dict.pkl\\\n",
    "    codet5_codenet_preds_lang_dict.pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-apache",
   "metadata": {},
   "source": [
    "### Load No-tok Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "proprietary-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_plbart = True\n",
    "merged_filtered_dict = get_prepro_filtered_dict(None, is_plbart)\n",
    "programs_dict = get_codenet_programs_dict(merged_filtered_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-pixel",
   "metadata": {},
   "source": [
    "### Pre-sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-attack",
   "metadata": {},
   "source": [
    "#### Get preds of unpaired programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-adrian",
   "metadata": {},
   "outputs": [],
   "source": [
    "script_path = \"get_codenet_preds.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fitted-access",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"codenet\"\n",
    "is_eval = False\n",
    "sample_size = 5\n",
    "temperature = 0.5\n",
    "tag = \"all\"\n",
    "model_type = \"plbart\"\n",
    "exp_suffix = \"_translation_exec_function/\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-shell",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lang_pairs and preds\n",
    "lang_pairs = []\n",
    "for lang1 in new_langs:\n",
    "    for lang2 in new_langs:\n",
    "        if lang2 != lang1:\n",
    "            lang_pairs.append((lang1, lang2))\n",
    "# small_programs_dict = {x:[\"haha\"] for x in new_langs}\n",
    "preds_lang_dict = get_preds_lang_dict_codenet(lang_pairs, model_type, device, programs_dict, \n",
    "                                      sample_size, temperature, data_name, tag, exp_suffix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-charm",
   "metadata": {},
   "source": [
    "#### Merge preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-reach",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_lang_dict_all = {}\n",
    "for lang in new_langs:\n",
    "    dic_path = cached_path + \"plbart_all_\" + lang + \"_codenet_preds_lang_dict.pkl\"\n",
    "    if not os.path.exists(dic_path):\n",
    "        continue\n",
    "    with open(dic_path, 'rb') as infile:\n",
    "        preds_lang_dict_batch = pickle.load(infile)\n",
    "        for k, v in preds_lang_dict_batch.items():\n",
    "            print(lang, k)\n",
    "            preds_lang_dict_all[k] = v\n",
    "print(preds_lang_dict_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "classified-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "plbart_sample_path = cached_path + 'plbart_codenet_preds_lang_dict.pkl'\n",
    "with open(plbart_sample_path, 'rb') as infile:\n",
    "     preds_lang_dict_plbart = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "essential-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "codet5_sample_path = cached_path + 'codet5_codenet_preds_lang_dict.pkl'\n",
    "with open(codet5_sample_path, 'rb') as infile:\n",
    "     preds_lang_dict_codet5 = pickle.load(infile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
