{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "primary-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tokenization_utils import *\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import jsonlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-decrease",
   "metadata": {},
   "source": [
    "# Run DOBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rubber-process",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Manage experiments\n",
    "model_path = \"/home/mingzhu/CodeModel/CodeGen/dobf_plus_denoising.pth\"  \n",
    "data_path_prefix = \"/home/mingzhu/CodeModel/g4g/pair_data_tok_full/\"\n",
    "# pair_data_tok_full pair_data_tok_1 pair_data_tok_-1\n",
    "exp_prefix = \"transcoder_dobf_g4g_program_transfer_\"\n",
    "model_exp_prefix = \"transcoder_dobf_g4g_beam_10_\"\n",
    "# transcoder_dobf_g4g_program_transfer_ transcoder_dobf_g4g_program_ transcoder_dobf_g4g_\n",
    "# transcoder_dobf_g4g_beam_10_ transcoder_dobf_g4g_beam_10_3r_\n",
    "\n",
    "langs = file_extensions.keys()\n",
    "# langs = ['Java', \"C++\", \"C#\"] # \"Python\"\n",
    "\n",
    "prefix = \"transcoder_dobf_g4g_\"\n",
    "prefix = \"transcoder_dobf_g4g_newline_\"\n",
    "\n",
    "# Train dobf on snippets\n",
    "model_path = \"/home/mingzhu/CodeModel/CodeGen/dobf_plus_denoising.pth\"  \n",
    "data_path_prefix = \"/home/mingzhu/CodeModel/g4g/pair_data_tok_1/\"\n",
    "exp_prefix = prefix + \"beam_5_\"\n",
    "model_exp_prefix = \"\"\n",
    "max_epoch = 50\n",
    "max_len = 100\n",
    "beam_size = 5\n",
    "# get_train_commands(langs, model_path, data_path_prefix, exp_prefix, model_exp_prefix,\n",
    "#                        max_epoch=max_epoch, max_len=max_len, beam_size=beam_size,\n",
    "#                        is_reloaded=True, is_dobf=True, is_transferred=False, is_print=True)\n",
    "\n",
    "# Train dobf on program\n",
    "model_path = \"/home/mingzhu/CodeModel/CodeGen/dobf_plus_denoising.pth\"  \n",
    "data_path_prefix = \"/home/mingzhu/CodeModel/g4g/pair_data_tok_full/\"\n",
    "exp_prefix = prefix + \"program_\"\n",
    "model_exp_prefix = \"\"\n",
    "max_epoch = 50\n",
    "max_len = 400\n",
    "beam_size = 5\n",
    "# get_train_commands(langs, model_path, data_path_prefix, exp_prefix, model_exp_prefix,\n",
    "#                        max_epoch=max_epoch, max_len=max_len, beam_size=beam_size,\n",
    "#                        is_reloaded=True, is_dobf=True, is_transferred=False, is_print=True)\n",
    "\n",
    "# Train dobf on program with pre-trained snippet model\n",
    "model_path = \"/home/mingzhu/CodeModel/CodeGen/dobf_plus_denoising.pth\"  \n",
    "data_path_prefix = \"/home/mingzhu/CodeModel/g4g/pair_data_tok_full/\"\n",
    "exp_prefix = prefix + \"program_transfer_\"\n",
    "model_exp_prefix = prefix + \"beam_10_\"\n",
    "max_epoch = 50\n",
    "max_len = 400\n",
    "beam_size = 5\n",
    "get_train_commands(langs, model_path, data_path_prefix, exp_prefix, model_exp_prefix,\n",
    "                       max_epoch=max_epoch, max_len=max_len, beam_size=beam_size,\n",
    "                       is_reloaded=True, is_dobf=True, is_transferred=True, is_print=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "direct-plasma",
   "metadata": {},
   "source": [
    "# Run Transcoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-stroke",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prefix = \"transcoder_g4g_\"\n",
    "prefix = \"transcoder_g4g_newline_\"\n",
    "# langs = ['Java', \"C++\", \"C#\"] # \"Python\"\n",
    "\n",
    "# Train transcoder on snippets\n",
    "model_path = \"/home/mingzhu/CodeModel/CodeGen/TransCoder_model_1.pth\"  \n",
    "data_path_prefix = \"/home/mingzhu/CodeModel/g4g/pair_data_tok_1/\"\n",
    "exp_prefix = prefix + \"1_\"\n",
    "model_exp_prefix = \"\"\n",
    "max_epoch = 50\n",
    "max_len = 100\n",
    "beam_size = 5\n",
    "get_train_commands(langs, model_path, data_path_prefix, exp_prefix, model_exp_prefix,\n",
    "                       max_epoch=max_epoch, max_len=max_len, beam_size=beam_size,\n",
    "                       is_reloaded=True, is_dobf=False, is_transferred=False, is_print=True)\n",
    "\n",
    "# Train transcoder on program\n",
    "model_path = \"/home/mingzhu/CodeModel/CodeGen/TransCoder_model_1.pth\"  \n",
    "data_path_prefix = \"/home/mingzhu/CodeModel/g4g/pair_data_tok_full/\"\n",
    "exp_prefix = prefix + \"program_\"\n",
    "model_exp_prefix = \"\"\n",
    "max_epoch = 50\n",
    "max_len = 400\n",
    "# beam_size = 5\n",
    "# get_train_commands(langs, model_path, data_path_prefix, exp_prefix, model_exp_prefix,\n",
    "#                        max_epoch=max_epoch, max_len=max_len, beam_size=beam_size,\n",
    "#                        is_reloaded=True, is_dobf=False, is_transferred=False, is_print=True)\n",
    "\n",
    "# Train transcoder on program with pre-trained snippet model\n",
    "model_path = \"/home/mingzhu/CodeModel/CodeGen/TransCoder_model_1.pth\"  \n",
    "data_path_prefix = \"/home/mingzhu/CodeModel/g4g/pair_data_tok_full/\"\n",
    "exp_prefix = prefix + \"program_transfer_\"\n",
    "model_exp_prefix = prefix + \"1_\"\n",
    "\n",
    "max_epoch = 50\n",
    "max_len = 400\n",
    "beam_size = 5\n",
    "# get_train_commands(langs, model_path, data_path_prefix, exp_prefix, model_exp_prefix,\n",
    "#                        max_epoch=max_epoch, max_len=max_len, beam_size=beam_size,\n",
    "#                        is_reloaded=True, is_dobf=False, is_transferred=True, is_print=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expanded-cheese",
   "metadata": {},
   "source": [
    "# Run Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-seeker",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Train transformer on snippets\n",
    "\n",
    "prefix = \"transformer_g4g_\"\n",
    "prefix = \"transformer_g4g_newline_\"\n",
    "\n",
    "model_path = \"/home/mingzhu/CodeModel/CodeGen/TransCoder_model_1.pth\"  \n",
    "data_path_prefix = \"/home/mingzhu/CodeModel/g4g/pair_data_tok_1/\"\n",
    "exp_prefix = prefix + \"1_\"\n",
    "model_exp_prefix = \"\"\n",
    "max_epoch = 50\n",
    "max_len = 100\n",
    "beam_size = 5\n",
    "# get_train_commands(langs, model_path, data_path_prefix, exp_prefix, model_exp_prefix,\n",
    "#                        max_epoch=max_epoch, max_len=max_len, beam_size=beam_size,\n",
    "#                        is_reloaded=False, is_dobf=False, is_transferred=False, is_print=True)\n",
    "\n",
    "# Train transformer on program\n",
    "model_path = \"/home/mingzhu/CodeModel/CodeGen/TransCoder_model_1.pth\"  \n",
    "data_path_prefix = \"/home/mingzhu/CodeModel/g4g/pair_data_tok_full/\"\n",
    "exp_prefix = prefix + \"program_\"\n",
    "model_exp_prefix = \"\"\n",
    "max_epoch = 50\n",
    "max_len = 400\n",
    "beam_size = 5\n",
    "get_train_commands(langs, model_path, data_path_prefix, exp_prefix, model_exp_prefix,\n",
    "                       max_epoch=max_epoch, max_len=max_len, beam_size=beam_size,\n",
    "                       is_reloaded=False, is_dobf=False, is_transferred=False, is_print=True)\n",
    "\n",
    "# Train transformer on program with pre-trained snippet model\n",
    "model_path = \"/home/mingzhu/CodeModel/CodeGen/TransCoder_model_1.pth\"  \n",
    "data_path_prefix = \"/home/mingzhu/CodeModel/g4g/pair_data_tok_full/\"\n",
    "exp_prefix = prefix + \"program_transfer_\"\n",
    "model_exp_prefix = prefix + \"1_\"\n",
    "max_epoch = 50\n",
    "max_len = 400\n",
    "beam_size = 5\n",
    "# get_train_commands(langs, model_path, data_path_prefix, exp_prefix, model_exp_prefix,\n",
    "#                        max_epoch=max_epoch, max_len=max_len, beam_size=beam_size,\n",
    "#                        is_reloaded=True, is_dobf=False, is_transferred=True, is_print=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-teach",
   "metadata": {},
   "source": [
    "# Read Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generic-robertson",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "exp_prefix = \"transcoder_g4g_newline_program_transfer\" \n",
    "# transcoder_dobf_g4g_ transcoder_g4g_program_ transcoder_g4g_1_\n",
    "# transcoder_dobf_g4g_beam_10_ transcoder_dobf_g4g_program_transfer_ transformer_g4g_1_\n",
    "# transformer_g4g_program_ transcoder_dobf_g4g_beam_10_3r_program_transfer_\n",
    "# transcoder_g4g_program_transfer_ transformer_g4g_program_transfer_\n",
    "# transcoder_dobf_g4g_program_transfer_codexglue_\n",
    "# transcoder_dobf_g4g_beam_10_codexglue_\n",
    "# transcoder_dobf_g4g_program_\n",
    "# transcoder_dobf_g4g_newline_beam_10_\n",
    "hypo_collection_path = \"./hypothesis_collection/Compilations/\" \n",
    "read_results(exp_prefix, dump_path) #, hypo_collection_path=hypo_collection_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-skill",
   "metadata": {},
   "source": [
    "### Format Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "particular-bachelor",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/mingzhu/CodeModel/CodeXGLUE/Code-Code/code-to-code-trans/\" #read_results\n",
    "# or\n",
    "path = \"/home/mingzhu/CodeModel/CodeXGLUE/Code-Code/code-to-code-trans/code\" #read_csv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-travel",
   "metadata": {},
   "source": [
    "### Get Exact Match (EM) of each experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-relevance",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_prefix = \"transcoder_dobf_g4g_beam_10_\" \n",
    "\n",
    "read_results(exp_prefix, dump_path, \n",
    "                 print_result=False, print_em=True, print_copy=False, \n",
    "                 hypo_collection_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "academic-adventure",
   "metadata": {},
   "source": [
    "### Get Naive Copy of each language pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-surprise",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"~/CodeModel/CodeGen_cwd/huggingface_models/run_naive_copy.sh\"\n",
    "# just run the above script\n",
    "# bash run_naive_copy.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stuck-apparatus",
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_copy_snippet = \"./huggingface_models/naive_copy_snippet.txt\"\n",
    "naive_copy_program = \"./huggingface_models/naive_copy_program.txt\"\n",
    "\n",
    "nc_dict_snippet = get_nc_dict(naive_copy_snippet)\n",
    "nc_dict_program = get_nc_dict(naive_copy_program)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-pacific",
   "metadata": {},
   "source": [
    "#### Obsolete code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-folder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get naive copy bleu\n",
    "# data_path_prefix = \"/home/mingzhu/CodeModel/g4g/pair_data_tok_full/\"\n",
    "data_path_prefix = program_data\n",
    "evaluator_path = \"/home/mingzhu/CodeModel/CodeXGLUE/Code-Code/code-to-code-trans/evaluator/\"\n",
    "# langs = file_extensions.keys()\n",
    "langs = [\"C++\", \"Java\", \"Python\", \"C#\", \"Javascript\", \"PHP\", \"C\"]\n",
    "for lang1 in langs:\n",
    "    for lang2 in langs:\n",
    "        if lang2 == lang1:\n",
    "            continue\n",
    "        langpair = lang1 + '-' + lang2\n",
    "        data_path = data_path_prefix + langpair + \"/\"\n",
    "        if not os.path.exists(data_path):\n",
    "            langpair = lang2 + '-' + lang1\n",
    "            data_path = data_path_prefix + langpair + \"/\"\n",
    "#         print(\"==============\", lang1, lang2, \"=============\")\n",
    "        testfile1 = \"test-\" + langpair + \"-tok\" + file_extensions[lang1]\n",
    "        testfile2 = \"test-\" + langpair + \"-tok\" + file_extensions[lang2]\n",
    "        em_command = \"python \" + evaluator_path + \"evaluator.py \" + \\\n",
    "                    \" -ref \" + data_path + testfile2 + \\\n",
    "                    \" -pre \" + data_path + testfile1\n",
    "        print(em_command)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-centre",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get naive copy codebleu\n",
    "# First cd codebleu_path\n",
    "data_path_prefix = snippet_data\n",
    "codebleu_path = \"/home/mingzhu/CodeModel/CodeXGLUE/Code-Code/code-to-code-trans/evaluator/CodeBLEU/\"\n",
    "for lang1 in langs:\n",
    "    for lang2 in langs:\n",
    "        if lang2 == lang1:\n",
    "            continue\n",
    "        langpair = lang1 + '-' + lang2\n",
    "        data_path = data_path_prefix + langpair + \"/\"\n",
    "        if not os.path.exists(data_path):\n",
    "            langpair = lang2 + '-' + lang1\n",
    "            data_path = data_path_prefix + langpair + \"/\"\n",
    "#         print(\"==============\", lang1, lang2, \"=============\")\n",
    "        testfile1 = \"test-\" + langpair + \"-tok\" + file_extensions[lang1]\n",
    "        testfile2 = \"test-\" + langpair + \"-tok\" + file_extensions[lang2]\n",
    "        codebleu_command = \"python \" + codebleu_path + \"calc_code_bleu.py \" + \\\n",
    "                    \" --refs \" + data_path + testfile2 + \\\n",
    "                    \" --hyp \" + data_path + testfile1 + \\\n",
    "                    \" --lang \" + lang_map[lang2]\n",
    "        print(codebleu_command)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forced-giving",
   "metadata": {},
   "source": [
    "# Baselines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-columbia",
   "metadata": {},
   "source": [
    "### Run on CodeXGlue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "independent-tuner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the data path to :\n",
    "path = \"/home/mingzhu/CodeModel/g4g/codeXglue_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-appraisal",
   "metadata": {},
   "source": [
    "### Run CodeBERT (and other Huggingface baselines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-carnival",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/mingzhu/CodeModel/CodeXGLUE/Code-Code/code-to-code-trans/code/\"\n",
    "# To run translation, use one script:\n",
    "# run_translation.sh\n",
    "path = \"/home/mingzhu/CodeModel/CodeXGLUE/Code-Code/code-to-code-trans/read_results.ipynb\"\n",
    "# Hypo collection;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "desirable-respect",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n",
      "tensor(2.1153, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "# Code Search\n",
    "path = \"/home/mingzhu/CodeModel/CodeXGLUE/Text-Code/NL-code-search-Adv/code/\"\n",
    "# run_code_search.sh is the script for all experiments\n",
    "# ../code2codesearch has all the experiments\n",
    "# ../code2codesearch/dataset has the data\n",
    "\n",
    "# bs=code_inputs.shape[0]\n",
    "# inputs=torch.cat((code_inputs,nl_inputs),0)\n",
    "# outputs=self.encoder(inputs,attention_mask=inputs.ne(1))[1]\n",
    "\n",
    "# code_vec=outputs[:bs]\n",
    "# nl_vec=outputs[bs:]\n",
    "# 先把nl和code叠起来，变成长度为2*batch_size的一个array\n",
    "# 通过encoder得到vector表示，outputs: (2*bs, d_model)\n",
    "# inputs: (2*bs, )\n",
    "# outputs: (2*bs, d_model)\n",
    "# code_vec: (bs, d_model)\n",
    "# nl_vec: (bs, d_model)\n",
    "# scores: (bs, 1, d_model) * (1, bs, d_model) = (bs, bs)\n",
    "\n",
    "nl_vec = torch.randn(3, 10, requires_grad=True)\n",
    "code_vec = torch.randn(3, 10, requires_grad=True)\n",
    "scores=(nl_vec[:,None,:]*code_vec[None,:,:]).sum(-1)\n",
    "print(scores.shape)\n",
    "loss1 = loss(scores, torch.arange(3))\n",
    "print(loss1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "presidential-conflict",
   "metadata": {},
   "source": [
    "# Code Viewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "snippet_data = \"/home/mingzhu/CodeModel/g4g/pair_data_tok_1/\"\n",
    "program_data = \"/home/mingzhu/CodeModel/g4g/pair_data_tok_full/\"\n",
    "code_viewer_path = \"/home/mingzhu/CodeModel/CodeGen/code_viewer/\"\n",
    "\n",
    "def view_code(lang1, lang2, data_type, tag):\n",
    "    lang_pair = lang1 + \"-\" + lang2\n",
    "    if not os.path.exists(program_data + lang_pair):\n",
    "        lang_pair = lang2 + \"-\" + lang1\n",
    "    fn = tag + \"-\" + lang_pair + file_extensions[lang2]\n",
    "    new_fn = data_type + \"-\" + fn + \".json\"\n",
    "    if data_type == \"snippet\":\n",
    "        code_path = snippet_data + lang_pair + \"/\" + fn\n",
    "    else:\n",
    "        code_path = program_data + lang_pair + \"/\" + fn\n",
    "\n",
    "    # if not os.path.exists(code_viewer_path + new_fn):\n",
    "    format_hypo_new(code_path, code_viewer_path + new_fn, lang2)\n",
    "    new_fmt = print_formatted_code(code_viewer_path+new_fn, True)\n",
    "    return\n",
    "\n",
    "def view_code_mono(lang1, lang2, data_type, tag):\n",
    "    lang_pair = lang1 + \"-\" + lang2\n",
    "    if not os.path.exists(program_data + lang_pair):\n",
    "        lang_pair = lang2 + \"-\" + lang1\n",
    "    fn = tag + \"-\" + lang_pair + file_extensions[lang2]\n",
    "    new_fn = data_type + \"-\" + fn.split(\".\")[0] + \".json\"\n",
    "    if data_type == \"snippet\":\n",
    "        code_path = snippet_data + lang_pair + \"/\" + fn\n",
    "    else:\n",
    "        code_path = program_data + lang_pair + \"/\" + fn\n",
    "\n",
    "    # if not os.path.exists(code_viewer_path + new_fn):\n",
    "    format_hypo_new(code_path, code_viewer_path + new_fn, lang2)\n",
    "    new_fmt = print_formatted_code(code_viewer_path+new_fn, True)\n",
    "    return\n",
    "\n",
    "lang1 = \"Python\"\n",
    "lang2 = \"Java\"\n",
    "data_type = \"program\" #snippet\n",
    "tag = \"test\" # train valid\n",
    "\n",
    "view_code(lang1, lang2, data_type, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "independent-broadway",
   "metadata": {},
   "source": [
    "# Stand-alone Detokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "secondary-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On Dhruv machine\n",
    "path = \"/home/reddy/ming/CodeModel/code_prepro.ipynb\"\n",
    "# On rail machine\n",
    "path = \"/home/mingzhu/CodeModel/CodeBERT/GraphCodeBERT/translation/code_prepro.ipynb\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
