{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "healthy-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "instant-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./huggingface_models/')\n",
    "sys.path.append('./utils/')\n",
    "from sample_utils import *\n",
    "from inference_utils import *\n",
    "from codenet_process_utils import *\n",
    "from self_training_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "conditional-sending",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "difficult-imaging",
   "metadata": {},
   "source": [
    "### Filtering:\n",
    "1. remove duplicated preds: get_dedup_preds\n",
    "2. filter by type-matching: prep_exec_hypo_codenet\n",
    "3. filter by compilation: get_hypo_call_list\n",
    "\n",
    "We get hypo call_dict in this step. \\\n",
    "call_list contains info about the processed hypos in lang2.\\\n",
    "```\n",
    "call_list = [programs, processed_results, result_keys, error_type_dict]\n",
    "call_dict[(lang1, lang2)] = [new_preds, functions, function_id_dict, call_list]\n",
    "```\n",
    "\n",
    "### Cached Files\n",
    "- Hypo call_dict\\\n",
    "    plbart_codenet_lang_pair_call_dict.pkl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-apache",
   "metadata": {},
   "source": [
    "### Load No-tok Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "proprietary-philadelphia",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_plbart = True\n",
    "merged_filtered_dict = get_prepro_filtered_dict(None, is_plbart)\n",
    "programs_dict = get_codenet_programs_dict(merged_filtered_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-cigarette",
   "metadata": {},
   "source": [
    "#### Get Import Str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "comparable-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_str_dict = {}\n",
    "for lang in new_langs:\n",
    "    all_imports, import_str = get_common_imports(lang, merged_filtered_dict)\n",
    "    import_str_dict[lang] = import_str\n",
    "import_str_dict[\"Java\"] = java_imports_str\n",
    "import_str_dict[\"C#\"] = csharp_imports_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-secretary",
   "metadata": {},
   "source": [
    "### Merge Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ethical-butterfly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mingzhu/CodeModel/CodeGen_cwd/cached_files/codet5_full_C++_codenet_2preds_lang_dict.pkl\n",
      "C++ ('C++', 'C#')\n",
      "/home/mingzhu/CodeModel/CodeGen_cwd/cached_files/codet5_full_Java_codenet_1preds_lang_dict.pkl\n",
      "Java ('C#', 'Java')\n",
      "Java ('C#', 'Python')\n",
      "Java ('C#', 'C++')\n",
      "Java ('Java', 'C#')\n",
      "Java ('Java', 'Python')\n",
      "Java ('Java', 'C++')\n",
      "/home/mingzhu/CodeModel/CodeGen_cwd/cached_files/codet5_full_Java_codenet_preds_lang_dict.pkl\n",
      "Java ('C', 'Java')\n",
      "Java ('C', 'Python')\n",
      "Java ('C', 'C#')\n",
      "Java ('C', 'C++')\n",
      "Java ('Java', 'C')\n",
      "/home/mingzhu/CodeModel/CodeGen_cwd/cached_files/codet5_full_Python_codenet_preds_lang_dict.pkl\n",
      "Python ('C', 'Java')\n",
      "Python ('C', 'Python')\n",
      "Python ('C', 'C#')\n",
      "Python ('C', 'C++')\n",
      "Python ('Java', 'C')\n",
      "Python ('Python', 'C')\n",
      "/home/mingzhu/CodeModel/CodeGen_cwd/cached_files/codet5_full_C#_codenet_1preds_lang_dict.pkl\n",
      "C# ('C#', 'Java')\n",
      "C# ('C#', 'Python')\n",
      "C# ('C#', 'C++')\n",
      "/home/mingzhu/CodeModel/CodeGen_cwd/cached_files/codet5_full_C#_codenet_preds_lang_dict.pkl\n",
      "C# ('C', 'Java')\n",
      "C# ('C', 'Python')\n",
      "C# ('C', 'C#')\n",
      "C# ('C', 'C++')\n",
      "C# ('Java', 'C')\n",
      "C# ('Python', 'C')\n",
      "C# ('C#', 'C')\n",
      "/home/mingzhu/CodeModel/CodeGen_cwd/cached_files/codet5_full_C_codenet_preds_lang_dict.pkl\n",
      "C ('C', 'Java')\n",
      "C ('C', 'Python')\n",
      "C ('C', 'C#')\n",
      "C ('C', 'C++')\n",
      "dict_keys([('C++', 'C#'), ('C#', 'Java'), ('C#', 'Python'), ('C#', 'C++'), ('Java', 'C#'), ('Java', 'Python'), ('Java', 'C++'), ('C', 'Java'), ('C', 'Python'), ('C', 'C#'), ('C', 'C++'), ('Java', 'C'), ('Python', 'C'), ('C#', 'C')])\n"
     ]
    }
   ],
   "source": [
    "preds_lang_dict_all = {}\n",
    "for lang in new_langs:\n",
    "    for i in [1, 2, \"\"]:\n",
    "        dic_path = cached_path + \"codet5_full_\" + lang + \"_codenet_\" + str(i) + \"preds_lang_dict.pkl\"\n",
    "        if not os.path.exists(dic_path):\n",
    "            continue\n",
    "        print(dic_path)\n",
    "        with open(dic_path, 'rb') as infile:\n",
    "            preds_lang_dict_batch = pickle.load(infile)\n",
    "            for k, v in preds_lang_dict_batch.items():\n",
    "                print(lang, k)\n",
    "                preds_lang_dict_all[k] = v\n",
    "print(preds_lang_dict_all.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "rising-stretch",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n"
     ]
    }
   ],
   "source": [
    "print(len(preds_lang_dict_all.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "associate-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "plbart_sample_path = cached_path + 'codet5_full_codenet_preds_lang_dict.pkl'\n",
    "with open(plbart_sample_path, 'wb') as outfile:\n",
    "     pickle.dump(preds_lang_dict_all, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "growing-schedule",
   "metadata": {},
   "source": [
    "### Load Pre-Sampled Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "classified-robin",
   "metadata": {},
   "outputs": [],
   "source": [
    "plbart_sample_path = cached_path + 'plbart_codenet_preds_lang_dict.pkl'\n",
    "with open(plbart_sample_path, 'rb') as infile:\n",
    "     preds_lang_dict_plbart = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "essential-satin",
   "metadata": {},
   "outputs": [],
   "source": [
    "codet5_sample_path = cached_path + 'codet5_codenet_preds_lang_dict.pkl'\n",
    "with open(codet5_sample_path, 'rb') as infile:\n",
    "     preds_lang_dict_codet5 = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acoustic-billy",
   "metadata": {},
   "outputs": [],
   "source": [
    "codet5_sample_path = cached_path + 'codet5_codenet_preds_lang_dict.pkl'\n",
    "with open(codet5_sample_path, 'rb') as infile:\n",
    "     preds_lang_dict_codet5 = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-faith",
   "metadata": {},
   "source": [
    "### Filter Generated Hypotheses by Type-Matching and Compilation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dependent-correlation",
   "metadata": {},
   "source": [
    "#### Get call_dict for Hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-begin",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lang_pairs = [('Python', 'Java'), ('Python', 'C#'),\n",
    "            ('Java', 'C#'), ('Java', 'C++'), ('Java', 'C'), \n",
    "            ('C#', 'Java'), ('C#', 'Python'), ('C#', 'C++'), ('C#', 'C')]\n",
    "call_dict = {}\n",
    "for lang1, lang2 in lang_pairs:\n",
    "    print(lang1, lang2)\n",
    "    preds = preds_lang_dict_all[(lang1, lang2)]\n",
    "    # remove duplicated preds\n",
    "    new_preds = get_dedup_preds(preds)\n",
    "    # filter by type-matching (Todo)\n",
    "    functions, function_id_dict = prep_exec_hypo_codenet(new_preds, lang1, lang2, \n",
    "                                                                 merged_filtered_dict, model_type)\n",
    "    # filter by compilation\n",
    "    call_list = get_hypo_call_list(functions, lang2, import_str_dict)\n",
    "    call_dict[(lang1, lang2)] = [new_preds, functions, function_id_dict, call_list]\n",
    "    with open(cached_path + \"codenet_lang_pair_call_dict.pkl\", 'wb') as outfile:\n",
    "        pickle.dump(call_dict, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "raising-column",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(cached_path + \"plbart_full_codenet_lang_pair_call_dict.pkl\", 'rb') as infile:\n",
    "    call_dict = pickle.load(infile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "junior-broadway",
   "metadata": {},
   "source": [
    "#### Get all the filtered hypos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "developed-columbus",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'merged_filtered_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-f676d1f4c21b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlang1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcall_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mnew_preds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_id_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mfiltered_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_compiled_hypos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction_id_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerged_filtered_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfiltered_lang_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'merged_filtered_dict' is not defined"
     ]
    }
   ],
   "source": [
    "filtered_lang_dict = {}\n",
    "for lang1, lang2 in call_dict.keys():\n",
    "    new_preds, functions, function_id_dict, call_list = call_dict[(lang1, lang2)] \n",
    "    filtered_dict = get_compiled_hypos(call_list, function_id_dict, merged_filtered_dict)\n",
    "    filtered_lang_dict[(lang1, lang2)] = filtered_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-belgium",
   "metadata": {},
   "source": [
    "#### Separate pids that have filtered hypos and pids that don't"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_dict = {}\n",
    "non_empty_dict = {}\n",
    "for lang1, lang2 in filtered_lang_dict.keys():\n",
    "    non_empty_dict[(lang1, lang2)] = []\n",
    "    empty_dict[(lang1, lang2)] = []\n",
    "    filtered_dict = filtered_lang_dict[(lang1, lang2)]\n",
    "    for pid, inds in filtered_dict.items():\n",
    "        if len(inds) > 0:\n",
    "            non_empty_dict[(lang1, lang2)].append(pid)\n",
    "        else:\n",
    "            empty_dict[(lang1, lang2)].append(pid)\n",
    "    print(lang1, lang2, len(non_empty_dict[(lang1, lang2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collective-update",
   "metadata": {},
   "source": [
    "### Resampling for pids that doesn't have filtered hypo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-roulette",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sampling_filtering_compilation(pids, eval_examples, eval_features, function_id_lang_dic,\n",
    "                       reverse_map_dict, result_id_dict_gold, lang, model_type, model, tokenizer, args, device,\n",
    "                       decoder_sid=None, is_eval=True, num_samples=5, temperature=0.5):\n",
    "    selected_eval_examples, selected_eval_dataloader = get_eval_data_by_pid(eval_examples, eval_features, \n",
    "                                                               pids, reverse_map_dict, args.eval_batch_size)\n",
    "    torch.cuda.empty_cache()\n",
    "    preds, eval_result = generation_multiple(selected_eval_examples, \n",
    "                                             selected_eval_dataloader, \n",
    "                                             model, tokenizer, args, device, \n",
    "                                             decoder_sid, is_eval, num_samples, temperature)\n",
    "    programs, program_id_dict, program_dict = prep_exec_hypo(preds, pids,\n",
    "                                                             function_id_lang_dic, lang, model_type)\n",
    "    lang_results = p_map(file_executors[lang], programs)\n",
    "    result_id_dict, result_key_dict, error_type_dict = result_mapping(lang_results, program_id_dict, \n",
    "                                                                      pids, lang)\n",
    "    buggy_pids, failed_test_pids, passed_hypo_dict = hypo_filtering(result_id_dict, \n",
    "                                                                    result_id_dict_gold, \n",
    "                                                                    result_key_dict, \n",
    "                                                                    program_dict)\n",
    "    print(len(buggy_pids),len(failed_test_pids), len(passed_hypo_dict), len(pids))\n",
    "    return buggy_pids, failed_test_pids, passed_hypo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "disturbed-guinea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resamples for pids in empty_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "frank-walter",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:01<00:00, 76.87it/s]\n"
     ]
    }
   ],
   "source": [
    "lang1 = \"C#\"\n",
    "lang2 = \"C++\"\n",
    "preds = preds_lang_dict_all[(lang1, lang2)][:100]\n",
    "new_preds = get_dedup_preds(preds)\n",
    "functions, function_id_dict = prep_exec_hypo_codenet(new_preds, lang1, lang2, \n",
    "                                                            merged_filtered_dict, model_type)\n",
    "# call_list = get_hypo_call_list(functions, lang2)\n",
    "# filtered_dict = get_compiled_hypos(call_list, function_id_dict, merged_filtered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "sustained-carry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f550c3aacc74c209afe0f7cbb87ad79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=426.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "C++ error 348 0.8169014084507042\n",
      "C++ timeout 0 0.0\n",
      "C++ empty 78 0.18309859154929578\n",
      "C++ other 0 0.0\n",
      "C++ good 0 0.0\n"
     ]
    }
   ],
   "source": [
    "call_list = get_hypo_call_list(functions, lang2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "computational-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dict = get_compiled_hypos(call_list, function_id_dict, merged_filtered_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-style",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (error_key, error)  in enumerate(zip(result_keys, processed_results)):\n",
    "    if error_key == \"error\":\n",
    "        if \"Compilation failed\" in error:\n",
    "            print(i, error)\n",
    "            break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
